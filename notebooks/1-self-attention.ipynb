{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "615389cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.1+cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d125b0",
   "metadata": {},
   "source": [
    "### Self Attention\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "775b2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self,\n",
    "    embed_dimension: Annotated[int, \"Dimension of embeddings for each word\"],\n",
    "    uses_bias: Annotated[bool, \"Requires bias are not\"] = True) -> None:\n",
    "        print(\"Self Attention under construction...\")\n",
    "        super().__init__()\n",
    "        self.embed_dimension = embed_dimension\n",
    "        self.uses_bias = uses_bias\n",
    "        self.w_q = nn.Linear(self.embed_dimension, self.embed_dimension, bias=uses_bias)\n",
    "        self.w_k = nn.Linear(self.embed_dimension, self.embed_dimension, bias=uses_bias)\n",
    "        self.w_v = nn.Linear(self.embed_dimension, self.embed_dimension, bias=uses_bias)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, sentence_sequences_embeddings:Annotated[torch.Tensor, \"Batch of vectors represent each & every words of a sentence\"]) -> torch.Tensor:\n",
    "        q = self.w_q(sentence_sequences_embeddings)\n",
    "        k = self.w_k(sentence_sequences_embeddings)\n",
    "        v = self.w_v(sentence_sequences_embeddings)\n",
    "\n",
    "        #(5, 6) (6,6) = (5, 6) is the dimension of q, k, v for example\n",
    "        attention_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.embed_dimension)\n",
    "        normalized_attention_scores = torch.softmax(attention_scores, dim=-1)\n",
    "        new_embedings = normalized_attention_scores @ v \n",
    "        return new_embedings\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdc7c884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self Attention under construction...\n"
     ]
    }
   ],
   "source": [
    "sa = SelfAttention(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d21f7cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self Attention under construction...\n",
      "Input shape : torch.Size([2, 3, 4])\n",
      "Output shape: torch.Size([2, 3, 4])\n",
      "Output tensor:\n",
      "tensor([[[ 0.2281,  0.3294,  0.5354,  0.5081],\n",
      "         [ 0.2245,  0.3259,  0.5349,  0.5073],\n",
      "         [ 0.2182,  0.3278,  0.5342,  0.4850]],\n",
      "\n",
      "        [[-0.0706,  0.0859,  0.4647,  0.5463],\n",
      "         [-0.1122,  0.0315,  0.4701,  0.4877],\n",
      "         [ 0.1383,  0.0632,  0.3782,  0.8658]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the parameters\n",
    "batch_size = 2        # Number of sentences\n",
    "seq_len = 3           # Number of tokens per sentence\n",
    "embed_dim = 4         # Embedding dimension (must match model)\n",
    "\n",
    "# Create dummy data: shape = (batch_size, seq_len, embed_dim)\n",
    "dummy_input = torch.randn(batch_size, seq_len, embed_dim)\n",
    "\n",
    "# Instantiate your SelfAttention class\n",
    "attention_layer = SelfAttention(embed_dimension=embed_dim)\n",
    "\n",
    "# Pass the dummy input through the attention layer\n",
    "output = attention_layer(dummy_input)\n",
    "\n",
    "# Print output\n",
    "print(\"Input shape :\", dummy_input.shape)     # Should be (2, 3, 4)\n",
    "print(\"Output shape:\", output.shape)          # Should be (2, 3, 4)\n",
    "print(\"Output tensor:\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ea5c431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 4])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = torch.Tensor([[\n",
    "  [[1, 0, 1, 0],   # Word 1\n",
    "    [0, 1, 0, 1],  # Word 2\n",
    "    [1, 1, 1, 1]], # Word 3\n",
    "\n",
    "[[1, 0, 1, 0],   # Word 1\n",
    "    [0, 1, 0, 1],  # Word 2\n",
    "    [1, 1, 1, 1]] \n",
    "]]) \n",
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af50e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 5])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([\n",
    "    [[1,2,3,4,5], [2,3,4,5,6,]],\n",
    "    [[1,2,3,4,5], [2,3,4,5,6,]],\n",
    "    [[1,2,3,4,5], [2,3,4,5,6,]]\n",
    "]\n",
    ")\n",
    "# Shape = (1, 3,2 ,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45ec5dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [3, 4]],\n",
       "\n",
       "        [[5, 6],\n",
       "         [7, 8]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "y.view( 2, 2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cdf753c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2],\n",
       "        [ 3,  4],\n",
       "        [ 5,  6],\n",
       "        [ 7,  8],\n",
       "        [ 9, 10],\n",
       "        [11, 12]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "data.view(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f17dec6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "y.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca5e772b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4],\n",
       "        [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.view(2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7b706a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.view(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8e1af807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2]],\n",
       "\n",
       "        [[3, 4]],\n",
       "\n",
       "        [[5, 6]],\n",
       "\n",
       "        [[7, 8]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.view(4,1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d4030c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2]],\n",
       "\n",
       "        [[3, 4]],\n",
       "\n",
       "        [[5, 6]],\n",
       "\n",
       "        [[7, 8]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (4, 1, -1)\n",
    "torch.tensor([\n",
    "    [[1, 2]],\n",
    "    [[3, 4]],\n",
    "    [[5, 6]],\n",
    "    [[7, 8]]\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a480f7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1, 2, 3, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c77d0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2ed0af5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717db67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]]) #(2, 2, 2)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "05821f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 2, 2])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f7751eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 2],\n",
       "          [3, 4]],\n",
       "\n",
       "         [[5, 6],\n",
       "          [7, 8]]]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "52fcbc47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 2],\n",
       "          [3, 4]]],\n",
       "\n",
       "\n",
       "        [[[5, 6],\n",
       "          [7, 8]]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1fea5fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[[1, 2, 3, 4]]])\n",
    "x.squeeze(0).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7edc69f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8,  9]],\n",
      "\n",
      "        [[10, 11, 12, 13, 14],\n",
      "         [15, 16, 17, 18, 19]],\n",
      "\n",
      "        [[20, 21, 22, 23, 24],\n",
      "         [25, 26, 27, 28, 29]],\n",
      "\n",
      "        [[30, 31, 32, 33, 34],\n",
      "         [35, 36, 37, 38, 39]]])\n",
      "Shape: torch.Size([4, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(4 * 2 * 5).reshape(4, 2, 5)\n",
    "print(x)\n",
    "print(\"Shape:\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ca1742a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0],\n",
       "        [ 1],\n",
       "        [ 2],\n",
       "        [ 3],\n",
       "        [ 4],\n",
       "        [ 5],\n",
       "        [ 6],\n",
       "        [ 7],\n",
       "        [ 8],\n",
       "        [ 9],\n",
       "        [10],\n",
       "        [11]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.arange(12).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c86c65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Attention is all you need",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
